2019-12-13 07:15:25,320 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
2019-12-13 07:15:25,805 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-12-13 07:15:25,822 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/kinyang/.staging/job_1576235822595_0012
2019-12-13 07:15:25,919 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2019-12-13 07:15:26,029 INFO input.FileInputFormat: Total input files to process : 1
2019-12-13 07:15:26,064 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2019-12-13 07:15:26,075 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2019-12-13 07:15:26,079 INFO mapreduce.JobSubmitter: number of splits:40
2019-12-13 07:15:26,234 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2019-12-13 07:15:26,255 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1576235822595_0012
2019-12-13 07:15:26,255 INFO mapreduce.JobSubmitter: Executing with tokens: []
2019-12-13 07:15:26,435 INFO conf.Configuration: resource-types.xml not found
2019-12-13 07:15:26,435 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2019-12-13 07:15:26,505 INFO impl.YarnClientImpl: Submitted application application_1576235822595_0012
2019-12-13 07:15:26,557 INFO mapreduce.Job: The url to track the job: http://localhost:8088/proxy/application_1576235822595_0012/
2019-12-13 07:15:26,557 INFO mapreduce.Job: Running job: job_1576235822595_0012
2019-12-13 07:15:33,674 INFO mapreduce.Job: Job job_1576235822595_0012 running in uber mode : false
2019-12-13 07:15:33,675 INFO mapreduce.Job:  map 0% reduce 0%
2019-12-13 07:15:53,860 INFO mapreduce.Job:  map 15% reduce 0%
2019-12-13 07:15:58,890 INFO mapreduce.Job: Task Id : attempt_1576235822595_0012_m_000008_0, Status : FAILED
Error: java.io.IOException: Cannot run program "chmod": error=23, Too many open files in system
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:938)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:865)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:252)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:232)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:331)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:320)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:351)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:405)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:975)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:652)
	at org.apache.hadoop.mapred.YarnChild.writeLocalJobFile(YarnChild.java:349)
	at org.apache.hadoop.mapred.YarnChild.configureTask(YarnChild.java:331)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:146)
Caused by: java.io.IOException: error=23, Too many open files in system
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 22 more

2019-12-13 07:15:58,910 INFO mapreduce.Job: Task Id : attempt_1576235822595_0012_m_000010_0, Status : FAILED
Error: java.io.IOException: Cannot run program "chmod": error=23, Too many open files in system
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:938)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:865)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:252)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:232)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:331)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:320)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:351)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:401)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:975)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:652)
	at org.apache.hadoop.mapred.YarnChild.writeLocalJobFile(YarnChild.java:349)
	at org.apache.hadoop.mapred.YarnChild.configureTask(YarnChild.java:331)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:146)
Caused by: java.io.IOException: error=23, Too many open files in system
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 22 more

2019-12-13 07:16:10,982 INFO mapreduce.Job:  map 25% reduce 0%
2019-12-13 07:16:15,002 INFO mapreduce.Job:  map 30% reduce 0%
2019-12-13 07:16:20,034 INFO mapreduce.Job: Task Id : attempt_1576235822595_0012_m_000016_0, Status : FAILED
Error: java.io.IOException: Cannot run program "chmod": error=23, Too many open files in system
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:938)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:865)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:508)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:493)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:511)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:654)
	at org.apache.hadoop.mapred.YarnChild.writeLocalJobFile(YarnChild.java:349)
	at org.apache.hadoop.mapred.YarnChild.configureTask(YarnChild.java:331)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:146)
Caused by: java.io.IOException: error=23, Too many open files in system
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 13 more

2019-12-13 07:16:27,071 INFO mapreduce.Job:  map 40% reduce 0%
2019-12-13 07:16:35,111 INFO mapreduce.Job:  map 43% reduce 13%
2019-12-13 07:16:40,144 INFO mapreduce.Job:  map 52% reduce 13%
2019-12-13 07:16:41,149 INFO mapreduce.Job:  map 52% reduce 14%
2019-12-13 07:16:44,168 INFO mapreduce.Job: Task Id : attempt_1576235822595_0012_m_000023_0, Status : FAILED
Error: java.io.IOException: Cannot run program "chmod": error=23, Too many open files in system
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:938)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:865)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:252)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:232)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:331)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:320)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:351)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:401)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:975)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:652)
	at org.apache.hadoop.mapred.YarnChild.writeLocalJobFile(YarnChild.java:349)
	at org.apache.hadoop.mapred.YarnChild.configureTask(YarnChild.java:331)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:146)
Caused by: java.io.IOException: error=23, Too many open files in system
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 22 more

2019-12-13 07:16:44,170 INFO mapreduce.Job: Task Id : attempt_1576235822595_0012_m_000022_0, Status : FAILED
Error: java.io.IOException: Cannot run program "chmod": error=23, Too many open files in system
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:938)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:865)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:252)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:232)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:331)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:320)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:351)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:401)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:975)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:652)
	at org.apache.hadoop.mapred.YarnChild.writeLocalJobFile(YarnChild.java:349)
	at org.apache.hadoop.mapred.YarnChild.configureTask(YarnChild.java:331)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:146)
Caused by: java.io.IOException: error=23, Too many open files in system
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 22 more

2019-12-13 07:16:44,171 INFO mapreduce.Job: Task Id : attempt_1576235822595_0012_m_000025_0, Status : FAILED
Error: java.io.IOException: Cannot run program "chmod": error=23, Too many open files in system
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:938)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:865)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:252)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:232)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:331)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:320)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:351)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:401)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:975)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:652)
	at org.apache.hadoop.mapred.YarnChild.writeLocalJobFile(YarnChild.java:349)
	at org.apache.hadoop.mapred.YarnChild.configureTask(YarnChild.java:331)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:146)
Caused by: java.io.IOException: error=23, Too many open files in system
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 22 more

2019-12-13 07:16:47,189 INFO mapreduce.Job:  map 52% reduce 17%
2019-12-13 07:16:50,210 INFO mapreduce.Job:  map 55% reduce 17%
2019-12-13 07:16:53,228 INFO mapreduce.Job:  map 55% reduce 18%
2019-12-13 07:16:54,234 INFO mapreduce.Job: Task Id : attempt_1576235822595_0012_m_000023_1, Status : FAILED
2019-12-13 07:16:55,239 INFO mapreduce.Job:  map 57% reduce 18%
2019-12-13 07:16:58,263 INFO mapreduce.Job:  map 65% reduce 18%
2019-12-13 07:16:59,269 INFO mapreduce.Job:  map 65% reduce 19%
2019-12-13 07:17:05,301 INFO mapreduce.Job:  map 65% reduce 22%
2019-12-13 07:17:08,316 INFO mapreduce.Job:  map 68% reduce 22%
2019-12-13 07:17:09,323 INFO mapreduce.Job:  map 70% reduce 22%
2019-12-13 07:17:11,334 INFO mapreduce.Job:  map 77% reduce 23%
2019-12-13 07:17:17,368 INFO mapreduce.Job:  map 77% reduce 26%
2019-12-13 07:17:22,394 INFO mapreduce.Job:  map 80% reduce 26%
2019-12-13 07:17:23,400 INFO mapreduce.Job:  map 82% reduce 26%
2019-12-13 07:17:25,413 INFO mapreduce.Job:  map 90% reduce 26%
2019-12-13 07:17:29,440 INFO mapreduce.Job:  map 90% reduce 30%
2019-12-13 07:17:34,464 INFO mapreduce.Job:  map 95% reduce 30%
2019-12-13 07:17:35,474 INFO mapreduce.Job:  map 100% reduce 31%
2019-12-13 07:17:39,496 INFO mapreduce.Job:  map 100% reduce 100%
2019-12-13 07:17:39,502 INFO mapreduce.Job: Job job_1576235822595_0012 completed successfully
2019-12-13 07:17:39,615 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=93602606
		FILE: Number of bytes written=196505369
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5347639502
		HDFS: Number of bytes written=113
		HDFS: Number of read operations=125
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Failed map tasks=7
		Killed map tasks=1
		Launched map tasks=47
		Launched reduce tasks=1
		Other local map tasks=7
		Data-local map tasks=40
		Total time spent by all maps in occupied slots (ms)=597073
		Total time spent by all reduces in occupied slots (ms)=84072
		Total time spent by all map tasks (ms)=597073
		Total time spent by all reduce tasks (ms)=84072
		Total vcore-milliseconds taken by all map tasks=597073
		Total vcore-milliseconds taken by all reduce tasks=84072
		Total megabyte-milliseconds taken by all map tasks=611402752
		Total megabyte-milliseconds taken by all reduce tasks=86089728
	Map-Reduce Framework
		Map input records=6685900
		Map output records=6685900
		Map output bytes=80230800
		Map output materialized bytes=93602840
		Input split bytes=4120
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=93602840
		Reduce input records=6685900
		Reduce output records=5
		Spilled Records=13371800
		Shuffled Maps =40
		Failed Shuffles=0
		Merged Map outputs=40
		GC time elapsed (ms)=6931
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=17418420224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5347635382
	File Output Format Counters 
		Bytes Written=113
Hadoop Percentage of Ratings MapReduce Time: 134394 ms
